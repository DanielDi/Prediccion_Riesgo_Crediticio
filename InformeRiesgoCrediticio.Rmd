---
title: "Informe de Riesgo Crediticio"
author: "Brayan Ortiz, Juan Peña, Thalea Hesse, Juan Falcon, Daniel Espinal"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE, warning=FALSE}
library(purrr)
library(feather)
library(arrow)
library(scorecard)
library(dplyr)    # alternatively, this also loads %>%
library(ggplot2)
library(klaR)
library(riskR)
library(corrplot)
library(creditmodel)
library(pROC)
library(knitr)
library(formattable)
library(RColorBrewer)
library(ggthemes)
library(cowplot)
library(stringr)

opts_chunk$set(echo = TRUE)
```
## Introducción

Los modelos estadísticos han sido utilizados como métodos prédictivos para la probabilidad de que un prestatario incumpla en el pago de sus obligaciones al prestamista [1]. La empresas dedicadas a las finanzas y, en particular, las prestamistas buscan métricas que les ayuden a evaluar si un cliente es un riesgo potencial para su negocio. Estas métricas se pueden resumir en un tarjeta de puntuación (scorecard), la cual presenta rangos de riesgo con base a los criterios críticos de cada empresa. En este proyecto se presenta el entrenamiento y la validación de un modelo de regresión logística para la probabilidad que una persona cumpla o incumpla los pagos. Después, este modelo se convierte en un scorecard el cual asigna unos puntos con base a las características que se seleccionaron de cada cliente.


## Datos

Los datos que se utilizan provienen de la base de datos *loan_data_2007_2014*. Esta base de datos contiene más de 450000 observaciones. Los datos corresponden a características de los préstamos a clientes que la compañía Lending Club realizó entre los años 2007 y 2014. Cuenta con 74 variables (numéricas y categóricas) que describen cada préstamo realizado. Sin embargo, luego de analizar las características predictoras, se encontró que varias de estas eran redundantes o estaban contenidas en otras, por lo que se descartaron del modelo. Además, la variable objetivo del modelo contenía varias categorías que describían si el estado de un cliente había sido bueno o malo, así que se decidió llevar esta variable a binaria (bueno o malo) y se construyó teniendo en cuenta las categorías que esta tenía. Finalmente, se obtiene un conjunto de datos con 22 variables: 21 predictoras y 1 objetivo. 


## Lectura y procesamiento de los datos

El procesamiento de los datos se llevó a cabo en Python. En este [link](https://github.com/DanielDi/Prediccion_Riesgo_Crediticio) se puede analizar al detalle cada procedimiento realizado. A continuación se presentan las ideas generales de lo que se realizó: 

* La variable objetivo *loan_status* contenía varias categorías para describir el estado bueno o malo, por lo que se agruparon y se generó una variable binaria. En particular, los datos que pertenecían a las categorías Default, Late (31-120 days), Charged Off, Does not meet the credit policy. Status: Charged Of; se marcaron como 1 para indicar que incumple. En cualquier otro caso, se marcó con un 0 para indicar que cumple.  
* Habían 29 registros que no tenían cuentas por lo que los valores en las características relacionadas a ingresos se completaron con ceros.  
* Las características que contenían cadenas de caracteres se convirtieron a numéricas para un fácil manejo.  
* Se eliminan las características redundantes o que no tienen información porque el cliente aún no tiene contrato con la entidad.  
* El porcentaje de datos NaNs en *emp_lenght* era de 4.5% y en *annual_inc* de 0.000858%. Para el primero se supone que la duración del empleo fue inferior a un año y, por tanto, los NaNs se reemplazaron por 0; para el segundo, se reemplazaron por la media de los datos en esta característica.


```{r, echo=FALSE, warning=FALSE,fig.cap = "Figura 1: Histograma variable Installments. Figura 2: Histograma variable Cantidad del préstamo ",fig.pos='H',fig.align='center'}
df = arrow::read_feather("datos_juntos.feather")

layout(matrix(c(1,2), ncol = 2))

hist(df$installment, xlab = "Installments (USD)", 
     main = "Histograma N°1", col = "lightcoral", 
     ylab = "Frecuencia") 

hist(df$loan_amnt, xlab = "Cantidad del préstamo (USD)", 
     main = "Histograma N°2", col = "lightcyan3",
     ylab = "Frecuencia")
```

## Datos de entrenamiento y prueba

Con el propósito de validar el modelo predictivo se realiza una división de los datos en entrenamiento y validación. Se utilizó una distribución del 75% para los datos de entrenamiento y 25% para validación. Este procedimiento se llevó a cabo con la ayuda del método *split_df* del paquete *scorecard*.  

Se presenta resumen de las variables númericas para los datos de entrenamiento:
```{r, echo=FALSE, message=FALSE,fig.cap = "Figura 3: Distribución de la partición de los datos",fig.pos='H',fig.align='center'}

tv <- split_df(df, y = "good_bad", ratio = c(0.75, 0.25),
               seed = 42, no_dfs = 2, name_dfs = c("train", "valid"))

train <- tv$train
valid <- tv$valid

train_sz <- nrow(train)
valid_sz <- nrow(valid)
sizes_dfs <- data.frame(Datos=c("Entrenamiento", "Validación"), 
                        value=c(train_sz, valid_sz))

ggplot(sizes_dfs, aes(x=Datos, y=value,fill=Datos))+
  geom_bar(stat = "identity")+
  ylab("Cantidad")+
  xlab("Partición de los Datos")+
  geom_text(aes(label=value), position = "stack", hjust = 0.5,vjust=-0.8, size=2.5)+
  scale_fill_manual(values=c("lightcoral",
                             "lightcyan3"))

```

## Agrupación de las variables en bins

Uno de los pasos más importantes para la creación del scorecard es lograr agrupar las variables en categorías. Este proceso se conoce como Bining. El cálculo de los bins se hace con el objetivo de calcular el Weight of Evidence Method (WoE) de las variables. En particular, se obtienen por separado los bins y los WoEs asociados a los bins para luego transformar el conjunto de datos con estos nuevos valores. La fórmula que se utiliza para la transformación de los datos en categóricos tiene la siguiente estructura: 
$$\begin{align}
\text{WoE:} \qquad &\ln \frac{\text{Distr Good}}{\text{Distr Bad}} \cdot 100  \\[10pt]
\end{align}$$

Estos cálculos se llevan a cabo con la ayuda de la función *woebin* del paquete *scorecard*. Para transformar los datos se utiliza *woebin_ply*. 

```{r, include=FALSE, message=FALSE}
# Agrupa los datos en bins
bins <- woebin(train, y = "good_bad", method = "tree")

# Aplica los bins al dataset train
train_bins <- woebin_ply(train, bins, to = "bin")
train_woes <- woebin_ply(train, bins)

# Aplica los bins al dataset valid
valid_bins <- woebin_ply(valid, bins, to = "bin")
valid_woes <- woebin_ply(valid, bins)

```

## Selección de variables

Comunmente en Estadística la selección de variables se realiza con los métodos AIC o BIC [2]. Sin embargo en los modelos de scorecard se emplean otra técnicas. En particular:  
1. Information Values  
2. Population Stability Analyses  
3. Correlation Analyses.

En el proyecto se hace uso principalmente de la primera, sin embargo con la tercera opción se refuerza la selección que se hizo.

### Información de valores
El cálculo de estos valores para cada variable se obtienen con la siguiente fórmula:  
$$\begin{align} \text{IV:} \qquad &\sum_{i=1}^n \left( \text{Distr Good}_i - \text{Distr Bad}_i \right) \cdot \ln \frac{\text{Distr Good}_i}{\text{Distr Bad}_i}\end{align}$$
Según [3], si el IV para una variable es inferior a 0.02, entonces esta variable se puede descartar del modelo. Para calcular estos valores se utilizó la función *feature_selector* del paquete *creditmodel*. Estas fueron las variables seleccionadas:   

```{r, echo=F, message=F, warning=F}
iv_vars <- feature_selector(dat_train = train_woes, dat_test = NULL, 
                            target = "good_bad", filter = "IV", iv_cp = 0.02,
                            vars_name = FALSE)

var_names <- sub("_woe", "", iv_vars$Feature)
aux_iv_vars <- data.frame(iv_vars$Feature, iv_vars$IV)
names(aux_iv_vars) <- c("Variable", "IV")
kable(aux_iv_vars)

# Filtrar los dataframes con las nuevas variables
train <- subset(train, select = append(var_names, "good_bad"))
train_bins <- subset(train_bins, select = append(paste(var_names, "_bin", sep=""), "good_bad"))
train_woes <- subset(train_woes, select = append(paste(var_names, "_woe", sep=""), "good_bad"))

valid <- subset(valid, select = append(var_names, "good_bad"))
valid_bins <- subset(valid_bins,  select = append(paste(var_names, "_bin", sep=""), "good_bad"))
valid_woes <- subset(valid_woes, select = append(paste(var_names, "_woe", sep=""), "good_bad"))
```

### Análisis de correlaciones

Se presenta las correlaciones de las variables que se eligieron con el método de IV. 

```{r, echo=FALSE, message=FALSE,fig.cap = "Figura 4: Gráfico de correlaciones de las variables elegidas por IV",fig.pos='H',fig.align='center' }
aux_train_woes <- train_woes
names(aux_train_woes) <- sub("_woe", "", names(aux_train_woes))
corr_train = cor(aux_train_woes)
corrplot(corr_train)
```

## Análisis de los agrupamientos

A las variables numéricas se les asignan unos intervalos para categorizarlas. A continuación se muestra un ejemplo con la variable *annual_inc*

```{r, echo=FALSE, message=FALSE, warning=F,fig.cap = "Figura 5: Distribución de los bins de anuual_inc con su respectiva etiqueta ",fig.pos='H',fig.align='center'}
# Muestra la información relevante de los bins 
kable(bins$annual_inc[, c(2, 4, 5, 6, 7, 8)])

# Grafica los bins
woebin_plot(bins, x = "annual_inc", line_value = "woe", show_iv = F)
```

La gráfica muestra los porcentajes de valores *positivos* y *negativos* para cada categoría creada. En este ámbito los positivos son la cantidad de personas que incumplen el pago, y los negativos son quienes los cumplen.


## Modelo de regresión logística

Los modelos de regresión logística son lo más usados para realizar predicciones de scorecard [4]. Por esta razón se utilizó este modelo, el cual se implementa con la función *glm*.

```{r, echo=FALSE, message=FALSE}

train_model <- glm(good_bad ~ ., data = train_woes, family = binomial())
summary(train_model)
```

### Métricas de rendimiento del modelo

El desempeño de los modelos de regresión logístico se puede medir de varias formas, cada una de ellas brinda información relevante para diferentes escenarios. Sin embargo, las cuatro métricas más usadas para este análisis son: **accuracy**, **precision**, **recall** y **F1-score**. Adicionalmente, se tiene **confusion matrix**, es una técnica sencilla para visualizar el rendimiento de la clasificación de los modelos. A continuación se presentan estas métricas y la gráfica del ROC para determinar cómo se comportan las predicciones entre buenas y malas. 

```{r, echo=FALSE, message=FALSE, warning=F,fig.cap = "Figura 6: Gráfico ROC. Figura 7: Gráfico de rendimiento F1-score",fig.pos='H',fig.align='center'}

valid_woes$prediction <- predict(train_model, valid_woes, type = "response")

train_woes$prediction <- predict(train_model, train_woes, type = "response")

metrics <- perf_eva(valid_woes$prediction, valid_woes$good_bad,
         show_plot = c("roc", "f1"))
```


Con base a esta tabla se puede determinar un AUC de `r metrics$binomial_metric$dat[,"AUC"]`. Para tener valores númericos se presentan las siguientes métricas:
```{r, echo=F, message=F}
kable(metrics$binomial_metric$dat)
```


También se presenta la distribución de las probabilidades predichas, agrupas con las etiquetas reales: 


```{r, echo=FALSE, message=FALSE, warning=F,fig.cap = "Figura 8: Distribución de las probabilidades predichas con su respectiva etiqueta",fig.pos='H',fig.align='center'}

gg1 <- ggplot( valid_woes, aes( prediction, color = as.factor(good_bad) )) + 
geom_density( size = 0.7 ) +
ggtitle( "Predicciones para el Conjunto de Entrenamiento" ) + 
scale_color_economist( name = "Datos", labels = c( "Negativo", "Positivo" ) ) + 
theme_economist()

gg1
```

Se puede observar que los valores positivos están solapados con los negativos y muy a la izquierda, lo cual no debería suceder. Un indicio de este comportamiento es que el porcentaje inicial de registros con la variable objetivo positiva es aproximadamente 8%.  

Para analizar más al detalle las predicciones del modelo se realiza una matriz de confusión.

```{r, echo=F, message=F, warning=F}
confusion_matrix <- perf_eva(valid_woes$prediction, valid_woes$good_bad,
         show_plot = NULL, binomial_metric = NULL, confusion_matrix = T)

conf_matrix <- confusion_matrix$confusion_matrix$dat
names(conf_matrix) <- c("Etiqueta", "Predicción = 0", "Predicción = 1", "Error")

kable(conf_matrix)

```

Como análisis final se calculan las métricas de precision, recall y F1 score con base en la matrix de confusión:

```{r, echo=F, message=F}
TN <- as.integer(conf_matrix[1,'Predicción = 0'])
FN <- as.integer(conf_matrix[2,'Predicción = 0'])

FP <- as.integer(conf_matrix[1,'Predicción = 1'])
TP <- as.integer(conf_matrix[2,'Predicción = 1'])

model_precision <- TP / (TP + FP)
model_recall <- TP / (TP + FN)
model_f1score <- 2 * model_precision * model_recall / (model_precision + model_recall)

mconf_metrics <- data.frame(model_precision, model_f1score, model_recall)

names(mconf_metrics) <- c("Precision", "F1 Score", "Recall")
kable(mconf_metrics)
```

## Modelo logístico a scorecard

El último paso para completar el modelo de riesgo es pasar del modelo logístico al scorecard. Esto se obtiene asignándoles unos puntos a cada bin calculado y el puntaje total es la suma sobre todas las característica que cumpla el registro en cuestión. Para implementar esta transformación se utiliza la función **scorecard**, a la cual se le pasa los bins calculados junto con el modelo previamente entrenado. Para predecir el puntaje se utiliza el método **scorecard_ply** al cual se le pasan las características del registro a predecir y el modelo de scorecard obtenido con la función scorecard. 


```{r, echo=FALSE, message=FALSE}
score_card_model <- scorecard(bins, train_model, points0 = 690)
```

### Predicción del puntaje con el modelo de scorecard

En esta sección se le pasalos datos y el modelo de scorecard. Este modelo devuelve un puntaje total y los puntajes que le asignó en cada característica.  

Un ejemplo de predicción con los datos de entrenamiento: 

```{r, echo=FALSE, message=FALSE}
train_score_predicted = scorecard_ply(train, score_card_model, 
                                      only_total_score = FALSE)
kable(head(train_score_predicted))
valid_score_predicted = scorecard_ply(valid, score_card_model, 
                                      only_total_score = FALSE)
```


Y con los datos de validación: 

```{r, echo=FALSE, message=FALSE}
valid_score_predicted = scorecard_ply(valid, score_card_model, 
                                      only_total_score = FALSE)
kable(head(valid_score_predicted))
```
### Variables que más afectan el perfil de riesgo

Veamos los puntos asignados por el scorecard a cada **bin** de cada variable.

```{r, echo=FALSE, message=FALSE}
do.call("bind_rows", score_card_model) %>% 
  slice(-1) %>% 
  dplyr::select(-count, -count_distr, -neg, -pos, -posprob, -woe, -bin_iv, -total_iv, -breaks, -is_special_values) %>% 
  mutate_if(is.numeric, function(x) {round(x, 3)}) %>% 
  mutate(bin = bin %>% 
           str_replace_all("\\%,%", " | ") %>%
           str_replace_all("\\[", "From ") %>% 
           str_replace_all("\\,", " to ") %>% 
           str_replace_all("\\)", "")) -> info_for_predictors

info_for_predictors %>% 
  knitr::kable(col.names = c("Variable", "BIN", "Points"))
```
Analizando los puntos que fueron asignados a cada **bin** de cada variable, llegamos a lo siguiente:

* Para la variable **int_rate** representa un riesgo bastante considerable un valor mayor o igual a 17, pero sus demás posibles valores no tienen el mismo comportamiento, siendo en la mayoría de los casos un valor positivo. Aunque esta variable ciertamente representa un riesgo, definitivamente no es la variable más riesgosa para el modelo.
* Para la variable **grade** 5 de sus 7 posibles categorías representan un riesgo para el modelo, por lo que esta podría representar una de las variables más riesgosas.
* Para las variable **porpuse** y **dti** se tienen puntajes (en valor absoluto) relativamente bajos por lo que, parece ser, no son las variables más riesgosas para el modelo.
* Para la variable **inq_last_6mths** se tienen valores negativos en su mayoría, por lo que, parece ser, en el modelo se considera como una variable de alto riesgo para el puntaje crediticio.

### Resumen del modelo de scorecard

Finalmente, se presenta el resumen de los puntajes que utilizó el modelo:

```{r, echo=FALSE, message=FALSE}

gt <- gains_table(valid_score_predicted$score, valid$good_bad, bin_num = 8)
kable(gt[, c(2,4,5,6,7,8,10,11)])

```
```{r, echo=FALSE, message=FALSE}
# Exportar datos necesarios a la App

# Se prueba una predicción
toPredcit <- data.frame(int_rate            = as.numeric(13.49), 
                        grade               = as.character("C"), 
                        #home_ownership      = as.character("OWN"),
                        annual_inc          = as.numeric(49200),
                        #verification_status = as.integer(1),
                        purpose             = as.character("other"), 
                        dti                 = as.numeric(20), 
                        inq_last_6mths      = as.numeric(1)
                        # earliest_cr_line  = as.integer(earliest_cr_days)
                        )

newScore <- scorecard_ply(toPredcit, score_card_model, only_total_score = FALSE)

# Se exporta el modelo
save(file="App/data/scorecardModelo.RData",
                              list=c("score_card_model"))

# Para comparar contra la población se junta el train y el valid y se le asigna
# el score a todas las filas
completeDF <- rbind(train, valid)

allScores <- scorecard_ply(completeDF, score_card_model, only_total_score = TRUE)

save(file="App/data/allScores.RData",
                              list=c("allScores"))

```

Se ilustra por medio de un Gráfico de barras de la cantidad de personas (las no Default) agrupadas por el puntaje obtenido: 

```{r, echo=F, message=F,fig.cap = "Figura 9: Gráfico de barras personas No Default por grupo",fig.pos='H',fig.align='center'}

df_gt <- gt[, c('bin', 'neg', 'pos')]

p <- ggplot(df_gt, aes(x = bin, y = neg)) + ylab("Cantidad")
p + geom_col(aes(x = bin, fill = factor(bin)))+
   geom_text(aes(label=neg), position = "stack", hjust = 0.5,vjust=-0.3, size=3)
```

Similarmente, se ilustran las personas con estado Default agrupadas por el puntaje obtenido:

```{r, echo=F, message=F,fig.cap = "Figura 10: Gráfico de barras personas Default por grupo",fig.pos='H',fig.align='center'}

p <- ggplot(df_gt, aes(x = bin, y = pos)) + ylab("Cantidad")
p + geom_col(aes(x = bin, fill = factor(bin)))+
   geom_text(aes(label=pos), position = "stack", hjust = 0.5,vjust=-0.3, size=3)
```

## Conclusiones

